{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request ID: 2300505793480487"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 361\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;66;03m# Execute the main function\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 361\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 351\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 351\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    352\u001b[0m     test_loss, correct, x_adv \u001b[38;5;241m=\u001b[39m test(model, device, test_loader)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# Test the model on the entire test set\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 176\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, epoch, log_interval, model_path)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(model, device, train_loader, optimizer, epoch, log_interval, model_path):\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;66;03m# Set the model to train mode\u001b[39;00m\n\u001b[0;32m--> 176\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbeam_width\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malpha\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargeted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargeted_attack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargeted_attack_label\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargeted_attack_confidence\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;66;03m# Loop through the data\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;66;03m# Send the data and target to the device\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[17], line 127\u001b[0m, in \u001b[0;36mLSTM_PGD_Beam_Search.train\u001b[0;34m(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;66;03m# Get the adversarial example\u001b[39;00m\n\u001b[0;32m--> 127\u001b[0m     x_adv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack_confidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x_adv, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minit_hidden(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]))\n",
      "Cell \u001b[0;32mIn[17], line 120\u001b[0m, in \u001b[0;36mLSTM_PGD_Beam_Search.attack\u001b[0;34m(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mattack\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# Get the perturbation\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m     perturbation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_width\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargeted_attack_confidence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# Get the adversarial example\u001b[39;00m\n\u001b[1;32m    122\u001b[0m     x_adv \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m perturbation\n",
      "Cell \u001b[0;32mIn[17], line 98\u001b[0m, in \u001b[0;36mLSTM_PGD_Beam_Search.pgd\u001b[0;34m(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpgd\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;66;03m# Get the batch size\u001b[39;00m\n\u001b[0;32m---> 98\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Create the perturbation\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     perturbation \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Path: pgd_jailbreak.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Define the model\n",
    "class LSTM_PGD_Beam_Search(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(LSTM_PGD_Beam_Search, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.beam_width = 5\n",
    "        self.max_length = 20\n",
    "        self.eps = 0.1\n",
    "        self.alpha = 0.1\n",
    "        self.targeted = False\n",
    "        self.target = None\n",
    "        self.target_label = None\n",
    "        self.target_confidence = None\n",
    "        self.targeted_attack = False\n",
    "        self.targeted_attack_label = None\n",
    "        self.targeted_attack_confidence = None\n",
    "        self.targeted_attack_perturbation = None\n",
    "        self.targeted_attack_perturbation_norm = None\n",
    "        self.targeted_attack_perturbation_norm_list = []\n",
    "        self.targeted_attack_perturbation_norm_list.append(0)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        out, hidden = self.lstm(x, hidden)\n",
    "        out = self.fc(out)\n",
    "        out = self.softmax(out)\n",
    "        return out, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size), torch.zeros(self.n_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "    def beam_search(self, x, hidden, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        batch_size = x.shape[0]\n",
    "        # Initialize the beam search\n",
    "        beam = [[[], 0, hidden]]\n",
    "        # Loop through the max length\n",
    "        for i in range(max_length):\n",
    "            # Create a new beam\n",
    "            new_beam = []\n",
    "            # Loop through the beam\n",
    "            for b in beam:\n",
    "                # If the sequence is not empty\n",
    "                if len(b[0]) > 0:\n",
    "                    # If the sequence is finished\n",
    "                    if b[0][-1] == 1:\n",
    "                        new_beam.append(b)\n",
    "                    # If the sequence is not finished\n",
    "                    else:\n",
    "                        # Forward pass\n",
    "                        out, hidden = self.forward(x, b[2])\n",
    "                        # Get the top k predictions\n",
    "                        topk = torch.topk(out[0, -1], beam_width)\n",
    "                        # Loop through the top k predictions\n",
    "                        for j in range(beam_width):\n",
    "                            # Get the new sequence\n",
    "                            new_seq = b[0].copy()\n",
    "                            new_seq.append(topk.indices[j].item())\n",
    "                            # Get the new probability\n",
    "                            new_prob = b[1] + topk.values[j].item()\n",
    "                            # Get the new hidden state\n",
    "                            new_hidden = (hidden[0][:, 0, :].unsqueeze(0).clone(), hidden[1][:, 0, :].unsqueeze(0).clone())\n",
    "                            # If the sequence is finished\n",
    "                            if new_seq[-1] == 1:\n",
    "                                # If the sequence is targeted\n",
    "                                if targeted:\n",
    "                                    # If the sequence is targeted\n",
    "                                    if new_seq == target:\n",
    "                                        new_beam.append([new_seq, new_prob, new_hidden])\n",
    "                                # If the sequence is not targeted\n",
    "                                else:\n",
    "                                    new_beam.append([new_seq, new_prob, new_hidden])\n",
    "                            # If the sequence is not finished\n",
    "                            else:\n",
    "                                new_beam.append([new_seq, new_prob, new_hidden])\n",
    "            # Sort the new beam\n",
    "            new_beam = sorted(new_beam, key=lambda x: x[1], reverse=True)\n",
    "            # Prune the new beam\n",
    "            beam = new_beam[:beam_width]\n",
    "        return beam\n",
    "    \n",
    "    def pgd(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        # Get the batch size\n",
    "        batch_size = x.shape[0]\n",
    "        # Create the perturbation\n",
    "        perturbation = torch.zeros(x.shape)\n",
    "        # Loop through the batch\n",
    "        for i in range(batch_size):\n",
    "            # Get the input and the target\n",
    "            x_i = x[i].unsqueeze(0).clone()\n",
    "            y_i = y[i].unsqueeze(0).clone()\n",
    "            # Get the initial hidden state\n",
    "            hidden = self.init_hidden(1)\n",
    "            # Beam search\n",
    "            beam = self.beam_search(x_i, hidden, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\n",
    "            # Get the best sequence\n",
    "            best_seq = beam[0][0]\n",
    "            # Get the best sequence as the perturbation\n",
    "            perturbation[i] = x_i - x_i\n",
    "            for j in range(len(best_seq)):\n",
    "                perturbation[i, j] = best_seq[j]\n",
    "        return perturbation\n",
    "    \n",
    "    def attack(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        # Get the perturbation\n",
    "        perturbation = self.pgd(x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\n",
    "        # Get the adversarial example\n",
    "        x_adv = x + perturbation\n",
    "        return x_adv\n",
    "    \n",
    "    def train(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        # Get the adversarial example\n",
    "        x_adv = self.attack(x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\n",
    "        # Forward pass\n",
    "        out, hidden = self.forward(x_adv, self.init_hidden(x.shape[0]))\n",
    "        # Loss\n",
    "        loss = F.nll_loss(out[:, -1], y)\n",
    "        return loss, x_adv\n",
    "    \n",
    "    def test(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        # Get the adversarial example\n",
    "        x_adv = self.attack(x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\n",
    "        # Forward pass\n",
    "        out, hidden = self.forward(x_adv, self.init_hidden(x.shape[0]))\n",
    "        # Loss\n",
    "        loss = F.nll_loss(out[:, -1], y)\n",
    "        # Accuracy\n",
    "        pred = out[:, -1].argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "        return loss, correct, x_adv\n",
    "    \n",
    "    def attack_all(self, x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence):\n",
    "        # Get the adversarial example\n",
    "        x_adv = self.attack(x, y, max_length, beam_width, eps, alpha, targeted, target, targeted_attack, targeted_attack_label, targeted_attack_confidence)\n",
    "        # Forward pass\n",
    "        out, hidden = self.forward(x_adv, self.init_hidden(x.shape[0]))\n",
    "        # Loss\n",
    "        loss = F.nll_loss(out[:, -1], y)\n",
    "        # Accuracy\n",
    "        pred = out[:, -1].argmax(dim=1, keepdim=True)\n",
    "        correct = pred.eq(y.view_as(pred)).sum().item()\n",
    "        return loss, correct, x_adv\n",
    "    \n",
    "\n",
    "config = {\n",
    "    'x': None, # input tensor\n",
    "    'y': None, # target tensor\n",
    "    'beam_width': 5, # beam width\n",
    "    'max_length': 20, # maximum length\n",
    "    'eps': 0.1, # epsilon\n",
    "    'alpha': 0.1, # alpha\n",
    "    'targeted': False, # targeted attack\n",
    "    'target': None, # target label\n",
    "    'targeted_attack': False, # targeted attack\n",
    "    'targeted_attack_label': None, # targeted attack label\n",
    "    'targeted_attack_confidence': None # targeted attack confidence\n",
    "}\n",
    "    \n",
    "# Train the model\n",
    "def train(model, device, train_loader, optimizer, epoch, log_interval, model_path):\n",
    "    # Set the model to train mode\n",
    "    model.train( config['x'], config['y'], config['max_length'], config['beam_width'], config['eps'], config['alpha'], config['targeted'], config['target'], config['targeted_attack'], config['targeted_attack_label'], config['targeted_attack_confidence'])\n",
    "    # Loop through the data\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Send the data and target to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        loss, x_adv = model.train(data, target, model.max_length, model.beam_width, model.eps, model.alpha, model.targeted, model.target, model.targeted_attack, model.targeted_attack_label, model.targeted_attack_confidence)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "        # Print the logs\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            # Save the model with the lowest loss\n",
    "            if loss.item() < model.best_loss:\n",
    "                model.best_loss = loss.item()\n",
    "                torch.save(model.state_dict(), model.model_path)\n",
    "                print('Model saved')\n",
    "    return model\n",
    "\n",
    "# Test the model\n",
    "def test(model, device, test_loader):\n",
    "    # Set the model to test mode\n",
    "    model.eval()\n",
    "    # Variables\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for data, target in test_loader:\n",
    "            # Send the data and target to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Forward pass\n",
    "            loss, corr, x_adv = model.test(data, target, model.max_length, model.beam_width, model.eps, model.alpha, model.targeted, model.target, model.targeted_attack, model.targeted_attack_label, model.targeted_attack_confidence)\n",
    "            # Calculate the test loss\n",
    "            test_loss += loss.item()\n",
    "            # Calculate the test accuracy\n",
    "            correct += corr\n",
    "    # Calculate the average test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # Print the test results\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, correct, x_adv\n",
    "\n",
    "# Test the model on the entire test set\n",
    "def test_all(model, device, test_loader):\n",
    "    # Set the model to test mode\n",
    "    model.eval()\n",
    "    # Variables\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for data, target in test_loader:\n",
    "            # Send the data and target to the device\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # Forward pass\n",
    "            loss, corr, x_adv = model.attack_all(data, target, model.max_length, model.beam_width, model.eps, model.alpha, model.targeted, model.target, model.targeted_attack, model.targeted_attack_label, model.targeted_attack_confidence)\n",
    "            # Calculate the test loss\n",
    "            test_loss += loss.item()\n",
    "            # Calculate the test accuracy\n",
    "            correct += corr\n",
    "    # Calculate the average test loss\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    # Print the test results\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    return test_loss, correct, x_adv\n",
    "\n",
    "# Plot the adversarial examples\n",
    "def plot_adversarial_examples(model, device, test_loader, classes, dataset, adv_examples_path):\n",
    "    # Set the model to test\n",
    "    model.eval()\n",
    "    # Initialize the lists\n",
    "    data_list = []\n",
    "    target_list = []\n",
    "    x_adv_list = []\n",
    "    pred_list = []\n",
    "    # Loop through the data\n",
    "    for data, target in test_loader:\n",
    "        # Send the data to the device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # Forward pass\n",
    "        loss, corr, x_adv = model.attack_all(data, target, model.max_length, model.beam_width, model.eps, model.alpha, model.targeted, model.target, model.targeted_attack, model.targeted_attack_label, model.targeted_attack_confidence)\n",
    "        # Append the data, target, adversarial example, and prediction\n",
    "        data_list.append(data)\n",
    "        target_list.append(target)\n",
    "        x_adv_list.append(x_adv)\n",
    "        pred_list.append(x_adv.argmax(dim=1))\n",
    "\n",
    "    # Concatenate the lists\n",
    "    data = torch.cat(data_list)\n",
    "    target = torch.cat(target_list)\n",
    "    x_adv = torch.cat(x_adv_list)\n",
    "    pred = torch.cat(pred_list)\n",
    "    # Plot the adversarial examples\n",
    "    for i in range(len(data)):\n",
    "        # Get the class name\n",
    "        class_name = classes[target[i]]\n",
    "        # Get the adversarial class name\n",
    "        adv_class_name = classes[pred[i]]\n",
    "        # Get the image\n",
    "        img = data[i].cpu().numpy()\n",
    "        # Get the adversarial image\n",
    "        adv_img = x_adv[i].cpu().numpy()\n",
    "        # Reshape the image\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        # Reshape the adversarial image\n",
    "        adv_img = np.transpose(adv_img, (1, 2, 0))\n",
    "        # Plot the image\n",
    "        plt.figure()\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(class_name)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # Plot the adversarial image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(adv_class_name)\n",
    "        plt.imshow(adv_img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "        # Save the plot\n",
    "        plt.savefig(adv_examples_path + '/adversarial_example_' + str(i) + '.png')\n",
    "        plt.close()\n",
    "    return\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    # Set the seed\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(0)\n",
    "    random.seed(0)\n",
    "    # Set the device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    max_epochs = 10\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.9\n",
    "    log_interval = 10\n",
    "    # Load the data\n",
    "    from torchvision import datasets, transforms\n",
    "    # Transform the data\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])\n",
    "    # Download and load the data\n",
    "    train_set = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "    test_set = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "    # Create the data loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "    # Classes\n",
    "    classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')\n",
    "    # Model path\n",
    "    model_path = 'models/lstm_pgd_beam_search_mnist.pt'\n",
    "    # Adversarial examples path\n",
    "    adv_examples_path = 'results/adversarial_examples'\n",
    "    # Create the model\n",
    "    model = LSTM_PGD_Beam_Search(28, 128, 10, 2).to(device)\n",
    "    # Optimizer\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "    # Model path\n",
    "    model.model_path = model_path\n",
    "    # Best loss\n",
    "    model.best_loss = np.inf\n",
    "    # Training loop\n",
    "    for epoch in range(1, max_epochs + 1):\n",
    "        model = train(model, device, train_loader, optimizer, epoch, log_interval, model_path)\n",
    "        test_loss, correct, x_adv = test(model, device, test_loader)\n",
    "    # Test the model on the entire test set\n",
    "    test_loss, correct, x_adv = test_all(model, device, test_loader)\n",
    "    # Plot the adversarial examples\n",
    "    plot_adversarial_examples(model, device, test_loader , classes, test_set, adv_examples_path)\n",
    "    return\n",
    "\n",
    "# Execute the main function\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
